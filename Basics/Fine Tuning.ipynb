{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Fine-Tuning:**\n",
    "\n",
    "Fine-tuning involves systematically experimenting with different hyperparameter values to optimize the performance of a machine learning model. For boosting algorithms like AdaBoost, Gradient Boosting, XGBoost, or LightGBM, there are several hyperparameters that can be tuned. Below, we'll discuss a general guide on how to fine-tune hyperparameters for boosting algorithms:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Identify Hyperparameters:\n",
    "   - **Learning Rate (or Step Size):** Controls the contribution of each weak learner to the final prediction. Lower values often lead to better generalization but require more boosting rounds.\n",
    "   - **Number of Estimators (or Boosting Rounds):** The number of weak learners (trees) to train. Increasing the number of estimators can improve performance but may lead to overfitting.\n",
    "   - **Tree-Specific Hyperparameters:** For algorithms involving decision trees (like XGBoost and LightGBM), consider parameters such as max depth, min child weight, subsample, colsample bytree, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split the Dataset:\n",
    "   - Divide your dataset into training, validation, and testing sets. The training set is used to train the model, the validation set helps in hyperparameter tuning, and the testing set is reserved for the final evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Choose a Hyperparameter Search Method:\n",
    "   - **Grid Search:** Specify a predefined set of hyperparameter values, and the algorithm will try all possible combinations. It's comprehensive but computationally expensive.\n",
    "   - **Random Search:** Specify a range for each hyperparameter, and the algorithm randomly samples combinations. It's less computationally expensive than grid search and often finds good results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Perform Hyperparameter Tuning:\n",
    "   - Use cross-validation on the training set to assess the model's performance for different hyperparameter values.\n",
    "   - Evaluate the model on the validation set for each set of hyperparameter values.\n",
    "   - Repeat this process for various combinations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate on the Testing Set:\n",
    "   - Once you've identified the best hyperparameters using the validation set, evaluate the model's performance on the testing set to get an unbiased estimate of its generalization ability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Analyze and Iterate:\n",
    "   - Analyze the impact of tuning on model performance, considering metrics like accuracy, precision, recall, or others relevant to your problem.\n",
    "   - Iterate if needed, adjusting the hyperparameter search space based on the results.\n",
    "\n",
    "\n",
    "This iterative process helps find the optimal set of hyperparameters for your boosting algorithm, leading to improved model performance on new, unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hyperparameter Tuning**\n",
    "**Using GridSearch Cross-validation and Randomized Search Cross-validation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter search space\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 4, 6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with Grid Search\n",
    "grid_search = GridSearchCV(gbc, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with Random Search\n",
    "random_search = RandomizedSearchCV(gbc, param_distributions=param_grid, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters from Grid Search:\", grid_search.best_params_)\n",
    "print(\"Best Hyperparameters from Random Search:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Checking Accuracy with One Boosting Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate a synthetic classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 4, 6]\n",
    "}\n",
    "\n",
    "# Create a GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Perform Randomized Search for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(gbc, param_distributions=param_grid, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = GradientBoostingClassifier(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy on the testing set\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy on Testing Set: {accuracy:.2f}\")\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
